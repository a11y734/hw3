from pathlib import Path
from typing import Optional
import sys

import pandas as pd
import streamlit as st

REPO_ROOT = Path(__file__).resolve().parents[1]
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

from spam_pipeline import artifacts, features, visualizations

st.set_page_config(page_title="ğŸ“§ åƒåœ¾éƒµä»¶æ™ºæ…§åˆ†æ", layout="wide")

# é è¨­æ”¹ç‚ºæŒ‡å‘è³‡æ–™å¤¾ï¼Œæœƒè‡ªå‹•å°‹æ‰¾æœ€åˆé©çš„æª”æ¡ˆ
DEFAULT_DATASET = Path("datasets")
DEFAULT_MODELS = Path("models")
DATASET_SOURCE_URL = (
    "https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-for-Cybersecurity"
    "/tree/master/Chapter03/datasets"
)


@st.cache_data(show_spinner=False)
def load_dataset(path: str, _mtime: float | None = None) -> pd.DataFrame:
    """è®€å– CSVï¼Œè‹¥åµæ¸¬åˆ°æ²’æœ‰è¡¨é ­å‰‡è‡ªå‹•è£œä¸Š label/textã€‚"""
    needs_header = False
    try:
        with open(path, "r", encoding="utf-8") as fh:
            first_line = fh.readline().strip().lower()
        prefix = first_line.replace('"', "").split(",", 1)[0]
        if prefix in {"ham", "spam"}:
            needs_header = True
    except OSError:
        pass

    if needs_header:
        df = pd.read_csv(path, header=None, names=["label", "text"], dtype=str)
    else:
        df = pd.read_csv(path)
    return df


@st.cache_resource(show_spinner=False)
def load_model(models_dir: str):
    bundle = artifacts.ArtifactBundle(Path(models_dir))
    pipeline = bundle.load("spam_pipeline")
    metadata = bundle.load_metadata()
    return pipeline, metadata


def resolve_dataset_path(path: Path) -> Optional[Path]:
    """å…è¨±è¼¸å…¥æª”æ¡ˆæˆ–è³‡æ–™å¤¾ï¼›è‹¥ç‚ºè³‡æ–™å¤¾è‡ªå‹•å°‹æ‰¾æœ€åˆé© CSVï¼ˆä»¥æª”æ¡ˆå¤§å°æ’åºï¼‰ã€‚"""
    if path.is_file() and path.suffix.lower() == ".csv":
        return path
    if path.is_dir():
        csvs = sorted(
            path.rglob("*.csv"),
            key=lambda p: p.stat().st_size if p.exists() else 0,
            reverse=True,
        )
        if csvs:
            return csvs[0]
    return None


def pick_dataset(local_path: Path) -> tuple[Optional[pd.DataFrame], Optional[Path]]:
    resolved = resolve_dataset_path(local_path)
    if resolved and resolved.exists():
        try:
            mtime = resolved.stat().st_mtime
        except OSError:
            mtime = None
        return load_dataset(str(resolved), mtime), resolved
    return None, None


def main():
    st.title("ğŸ“§ åƒåœ¾éƒµä»¶æ™ºæ…§åˆ†æå¥—ä»¶")
    st.write(
        "ä»¥ Packt ç¬¬ä¸‰ç« çš„åƒåœ¾éƒµä»¶ç¯„ä¾‹ç‚ºéˆæ„Ÿï¼Œæä¾›è³‡æ–™é è™•ç†ã€è©•ä¼°èˆ‡è¦–è¦ºåŒ–æµç¨‹ï¼Œ"
        "ä¸¦æ”¯æ´ CLI èˆ‡ Streamlit é›™ä»‹é¢ã€‚"
    )

    st.sidebar.header("è³‡æ–™ä¾†æº")
    dataset_path = st.sidebar.text_input("è³‡æ–™é›†è·¯å¾‘", str(DEFAULT_DATASET))
    data, resolved_path = pick_dataset(Path(dataset_path))
    if data is None:
        st.warning("æ‰¾ä¸åˆ°è³‡æ–™é›†ï¼Œè‡³å°‘å…ˆåŸ·è¡Œé è™•ç†è…³æœ¬æˆ–ä¸Šå‚³ CSVã€‚")
        return
    if data.empty:
        st.warning("è³‡æ–™é›†ç‚ºç©ºï¼Œè«‹æä¾›è‡³å°‘ 1 ç­†æ¨£æœ¬ã€‚")
        return

    # è‡ªå‹•æ¨æ¸¬æ¬„ä½é è¨­
    columns = list(data.columns)
    label_candidates = ["label", "category", "target", "class", "y"]
    text_candidates = ["text_clean", "text", "message", "sms", "v2"]
    def_idx_label = next((i for i, c in enumerate(columns) if c.lower() in label_candidates), 0)
    text_options = [c for c in columns if data[c].dtype == object]
    def_idx_text = next((i for i, c in enumerate(text_options) if c.lower() in text_candidates), 0 if text_options else 0)

    label_col = st.sidebar.selectbox("æ¨™ç±¤æ¬„ä½", options=columns, index=def_idx_label)
    text_col = st.sidebar.selectbox("æ–‡å­—æ¬„ä½", options=text_options or columns, index=def_idx_text)
    st.sidebar.subheader("è³‡æ–™é è¦½")
    st.sidebar.caption("å›ºå®šé¡¯ç¤ºå‰ 20 ç­†ã€‚")
    preview_rows = min(20, int(len(data)))
    max_top_tokens = int(len(data))

    st.sidebar.subheader("è©é »é¡¯ç¤º")
    token_slider_min = 5 if max_top_tokens >= 5 else 1
    token_slider_step = 5 if max_top_tokens >= 5 else 1
    top_token_limit = st.sidebar.slider(
        "Top-N tokensï¼ˆæ¯é¡åˆ¥ï¼‰",
        min_value=token_slider_min,
        max_value=max_top_tokens,
        value=min(20, max_top_tokens),
        step=token_slider_step,
    )

    st.subheader("è³‡æ–™æ¦‚æ³")
    table_height = min(700, 38 * preview_rows + 60)
    st.dataframe(data.head(preview_rows), use_container_width=True, height=table_height)
    st.caption(
        f"æ¨£æœ¬æ•¸ï¼š{len(data)} ï¼æ¬„ä½ï¼š{len(data.columns)} ï¼è³‡æ–™ä¾†æºï¼š[Packt Hands-On AI for Cybersecurity]"
        f"({DATASET_SOURCE_URL}) â†’ `{resolved_path or Path(dataset_path)}`"
    )
    st.caption("è³‡æ–™è¡¨åƒ…é¡¯ç¤ºå‰ N ç­†ï¼Œæ‰€æœ‰çµ±è¨ˆèˆ‡åœ–è¡¨ä»ä½¿ç”¨å®Œæ•´è³‡æ–™é›†ã€‚")

    counts = data[label_col].value_counts()
    col1, col2 = st.columns(2)
    with col1:
        st.metric("åƒåœ¾éƒµä»¶ï¼ˆSpamï¼‰æ•¸é‡", int(counts.get("spam", 0)))
    with col2:
        st.metric("æ­£å¸¸éƒµä»¶ï¼ˆHamï¼‰æ•¸é‡", int(counts.get("ham", 0)))
    st.caption(
        f"åˆ†é¡ç¸½æ•¸ï¼š{int(counts.sum())}ï¼ˆ= å…¨éƒ¨æ¨£æœ¬ {len(data)} ç­†ï¼‰ã€‚è‹¥ä¸ç›¸ç¬¦è«‹æª¢æŸ¥æ¨™ç±¤æ¬„ä½ã€‚"
    )

    st.subheader("è¦–è¦ºåŒ–")
    fig = visualizations.plot_class_distribution(data, label_col)
    st.pyplot(fig)

    st.markdown("### Top Tokens by Class")
    st.caption("ä½¿ç”¨å´é‚Š Top-N slider èª¿æ•´æ¯å€‹é¡åˆ¥é¡¯ç¤ºçš„ tokens æ•¸é‡ã€‚")
    top_tokens = features.top_tokens_by_class(data, label_col, text_col, topn=int(top_token_limit))
    non_empty = {label: items for label, items in top_tokens.items() if items}
    if non_empty:
        columns = st.columns(len(non_empty))
        for (label, items), column in zip(non_empty.items(), columns):
            column.plotly_chart(
                plot_top_tokens_by_label(label, items),
                use_container_width=True,
            )
    else:
        st.info("è©å½™çµ±è¨ˆä¸è¶³ï¼Œè«‹ç¢ºèªæ–‡å­—æ¬„ä½æ˜¯å¦å­˜åœ¨ã€‚")

    st.subheader("æ¨¡å‹ç‹€æ…‹")
    models_dir = st.sidebar.text_input("æ¨¡å‹ç›®éŒ„", str(DEFAULT_MODELS))
    model_text_col = None
    try:
        pipeline, metadata = load_model(models_dir)
        metrics = metadata.get("metrics", {})
        model_text_col = metadata.get("text_col")
        st.write(
            {
                "æ­£é¡åˆ¥": metadata.get("positive_label"),
                "æ±ºç­–é–¾å€¼": metrics.get("threshold"),
                "ç²¾ç¢ºç‡": metrics.get("precision"),
                "å¬å›ç‡": metrics.get("recall"),
                "F1": metrics.get("f1"),
                "æ–‡å­—æ¬„ä½ï¼ˆæ¨¡å‹ï¼‰": model_text_col,
            }
        )
        if model_text_col and model_text_col != text_col:
            st.info(
                f"æ¨¡å‹ä½¿ç”¨çš„æ–‡å­—æ¬„ä½ç‚º `{model_text_col}`ï¼Œèˆ‡å´æ¬„é¸å–çš„ `{text_col}` ä¸åŒï¼›æ¨è«–æœƒè‡ªå‹•æ”¹ç”¨æ¨¡å‹æ¬„ä½ã€‚"
            )
    except Exception as exc:  # noqa: BLE001
        st.info(f"è¼‰å…¥æ¨¡å‹å¤±æ•—æˆ–å°šæœªè¨“ç·´ï¼š{exc}")
        pipeline = None
        metadata = None

    st.subheader("å³æ™‚æ¨è«–")
    default_spam = "Free entry in 2 a wkly comp to win cash!"
    default_ham = "Are we still on for lunch today?"
    col_spam, col_ham = st.columns(2)
    with col_spam:
        if st.button("ä½¿ç”¨åƒåœ¾éƒµä»¶ç¯„ä¾‹"):
            st.session_state["candidate_text"] = default_spam
    with col_ham:
        if st.button("ä½¿ç”¨æ­£å¸¸éƒµä»¶ç¯„ä¾‹"):
            st.session_state["candidate_text"] = default_ham

    text_value = st.text_area("è¼¸å…¥è¨Šæ¯", value=st.session_state.get("candidate_text", ""))
    threshold = st.slider(
        "é–¾å€¼",
        min_value=0.1,
        max_value=0.9,
        value=float(metadata.get("metrics", {}).get("threshold", 0.5) if metadata else 0.5),
        step=0.01,
    )

    if st.button("é æ¸¬"):
        if pipeline is None:
            st.error("å°šæœªè¼‰å…¥æ¨¡å‹ï¼Œè«‹å…ˆè¨“ç·´æˆ–æ”¾ç½® artifactsã€‚")
        else:
            numeric_cols = metadata.get("numeric_cols", []) if metadata else []
            inference_text_col = model_text_col or text_col
            inference_df = build_inference_frame(text_value, inference_text_col, numeric_cols)
            prob = float(pipeline.predict_proba(inference_df)[:, 1])
            positive_label = metadata.get("positive_label", "spam")
            label = positive_label if prob >= threshold else f"é {positive_label}"
            st.success(f"é æ¸¬çµæœï¼š{label} ï¼æ©Ÿç‡ï¼š{prob:.3f}")
            st.progress(min(max(prob, 0), 1))


def build_inference_frame(text_value: str, text_col: str, numeric_cols: list[str]) -> pd.DataFrame:
    """å»ºç«‹å–®ç­†æ¨è«–è³‡æ–™ï¼Œç¢ºä¿æ¬„ä½ç¬¦åˆè¨“ç·´æµç¨‹ã€‚"""
    base = pd.DataFrame({text_col: [text_value]})
    if numeric_cols:
        derived = features.derive_text_features(base[text_col], prefix=text_col)
        for col in numeric_cols:
            if col not in derived.columns:
                derived[col] = 0.0
        base = pd.concat([base, derived[numeric_cols]], axis=1)
    return base


def plot_top_tokens_by_label(label: str, items: list[tuple[str, int]]):
    import plotly.express as px

    df = pd.DataFrame(items, columns=["token", "count"])
    return px.bar(
        df,
        x="count",
        y="token",
        orientation="h",
        title=f"Class: {label}",
        labels={"count": "æ¬¡æ•¸", "token": "è©å½™"},
    )


if __name__ == "__main__":
    main()
